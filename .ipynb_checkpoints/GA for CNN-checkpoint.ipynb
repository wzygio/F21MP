{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ef0186-fe31-4dc6-bd93-121be39500a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [深度学习框架] PyTorch核心 + TorchVision（含AMP混合精度）\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4720d125-ee79-4458-87d7-308ff90d3dfe",
   "metadata": {},
   "source": [
    "1. import torch:\n",
    "这是PyTorch的核心库，包含了所有的张量操作（类似于NumPy），并支持GPU加速。通过它，你可以进行数值计算、梯度计算和深度学习模型的训练。\n",
    "\n",
    "2. import torch.nn as nn:\n",
    "该模块提供了神经网络的各种基础组件，包括层（如卷积层、全连接层等）、损失函数（如交叉熵损失、均方误差损失等）以及常见的模型结构。nn是构建和训练神经网络时非常重要的工具集。\n",
    "\n",
    "3. import torch.optim as optim:\n",
    "这是PyTorch中用于优化器的模块。它包含了常见的优化算法（如SGD、Adam、RMSprop等），可以用来更新模型的参数。你将使用这些优化器来最小化损失函数，并通过梯度下降调整网络的权重。\n",
    "\n",
    "4. import torchvision:\n",
    "这是一个基于PyTorch的计算机视觉库，提供了大量的预训练模型（如ResNet、VGG等）以及用于数据处理和增强的工具。torchvision可以用来加载数据集（如ImageNet、CIFAR10等），并且为图像的加载、预处理提供了丰富的功能。\n",
    "\n",
    "5. import torchvision.transforms as transforms:\n",
    "这个模块用于图像的预处理和增强。在训练神经网络时，通常会对图像进行归一化、裁剪、旋转等变换，以增加数据多样性并提高模型的泛化能力。通过transforms，可以方便地定义和应用这些数据增强操作。\n",
    "\n",
    "6. from torch.cuda.amp import autocast, GradScaler:\n",
    "autocast和GradScaler是用于混合精度训练的工具。autocast允许在计算时自动选择较低精度（如FP16），从而加速训练而不显著损失精度；GradScaler用于缩放梯度，防止在使用低精度时出现梯度消失或溢出的情况。它们有助于减少显存消耗并提高计算效率，特别适用于GPU训练。\n",
    "\n",
    "7. from torchinfo import summary:\n",
    "summary是一个用于打印神经网络模型概况的工具，可以显示模型的层级结构、参数量和输出尺寸等信息。它类似于Keras中的model.summary()，可以帮助开发者快速查看模型的配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9100c32-f73a-4163-bdd2-c87dfbc23cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [进化计算框架] DEAP遗传算法库\n",
    "# [辅助模块] 模型分析/并发计算/资源管理\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "import pickle  # 保存最佳个体\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from deap import base, creator, tools, algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9ecfbd-4991-4839-af5b-803dc75c52d4",
   "metadata": {},
   "source": [
    "1. import random:\n",
    "Python的标准库之一，用于生成随机数。在本项目中，用于生成初始种群、选择个体、进行交叉和变异操作等。random模块提供了生成随机整数、浮点数以及从序列中随机选择元素的功能。\n",
    "\n",
    "2. import time:\n",
    "这是Python标准库中的时间模块。它提供了处理时间的功能，常用于计算代码执行的时间、设定延时等。在本项目中，可以用来记录每一代的训练时间，评估算法的效率。\n",
    "\n",
    "3. import gc:\n",
    "gc是Python的垃圾回收模块，用于手动触发垃圾回收操作。在进行深度学习训练时，特别是在使用大量内存的情况下，垃圾回收有助于释放不再使用的内存，防止内存泄漏，提高训练效率。\n",
    "\n",
    "4. import pickle:\n",
    "pickle是Python的序列化库，用于将Python对象转换为字节流（即序列化），以便将它们保存到磁盘上。它也可以将文件读取并恢复为Python对象。本项目中用来保存最佳个体（例如在遗传算法中保存最佳解决方案）或训练好的模型，以便后续加载使用。\n",
    "\n",
    "5. from concurrent.futures import ThreadPoolExecutor:\n",
    "ThreadPoolExecutor是Python的并发编程库，用于管理线程池并执行并行任务。通过使用线程池，可以在多个线程中并行执行任务，从而加速某些计算密集型或I/O密集型的操作。在遗传算法中，可以用来并行处理种群中的多个个体，提高算法的计算效率。\n",
    "\n",
    "6. from deap import base, creator, tools, algorithms:\n",
    "deap（Distributed Evolutionary Algorithms in Python）是一个用于构建和运行遗传算法的Python库。这个库提供了多种工具，用于快速实现遗传算法的基本元素。下面是具体模块的作用：\n",
    "- base: 用于定义遗传算法的基本构件，创建个体、种群等。\n",
    "- creator: 用于创建和定制适应度函数、个体类型等。例如，可以使用它来创建适应度函数和个体类。\n",
    "- tools: 提供了多种遗传算法的工具函数，比如选择策略、变异和交叉操作、种群初始化等。\n",
    "- algorithms: 提供了预定义的遗传算法框架，比如常见的遗传算法流程和算法的执行方式，可以直接调用这些算法来运行实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e51e5fe4-2a78-41d9-a80a-c806233dbecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d152557b-784b-4a6d-9f26-245429f67517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.1+cu117\n",
      "CUDA version: 11.7\n",
      "GPU count: 1\n",
      "GPU 0: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# 打印CUDA信息\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47c46ec-8297-4991-9d33-52a1daf28dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 确保 PyTorch 使用 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4d8e5-1da0-4198-8dbe-f5ba05f7e2dd",
   "metadata": {},
   "source": [
    "# 1 预训练CNN模型\n",
    "## 1-1 创建CNN模型\n",
    "这部分的任务是定义并训练一个CNN模型在CIFAR-10数据集上。  \n",
    "为了加速训练，我使用了如下几种手段，将训练时间从174s降低到了55s：\n",
    "1. 启用了FP16 计算（混合精度）：GradScaler()使计算使用 FP16（半精度浮点数），减少GPU占用，提高训练效率。\n",
    "2. Tesla T4的优势是显存，所以我进一步提升了batch_size的数量（从100到256）\n",
    "3. 启用 torch.backends.cudnn.benchmark：cuDNN可以优化输入数据shape固定的CNN 训练\n",
    "4. 优化trainloader:\n",
    "    - num_workers=4 → 增大数据加载进程数\n",
    "    - pin_memory=True → 减少 CPU-GPU 数据拷贝延迟\n",
    "    - prefetch_factor=2 → 预加载更多 batch 数据，加速训练\n",
    "5. 优化强化版的SGD作为Opitimizer，其收敛速度更快，适用于大规模训练：\n",
    "    - SGD(mini-batch)\n",
    "    - momentum(累计历史梯度)\n",
    "    - weight decay(权重正则化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71baff1-a3e5-49c3-a7a1-2369738d03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CNN模型：继承自nn.Module的类SimpleCNN。\n",
    "# nn.Module是PyTorch中所有神经网络模块的基类，继承它可以帮助你创建自定义的网络模型。\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    输入通道: 3 (RGB) → Conv1(32) → Conv2(64) → Conv3(128) → FC(10)\n",
    "    激活函数: ReLU\n",
    "    下采样: MaxPooling(2x2)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__() # 调用父类nn.Module的构造函数，确保PyTorch的内置机制能正常工作。\n",
    "\n",
    "        # 输入通道数（in_channels）\n",
    "        # 输出通道数（out_channels）\n",
    "        # 卷积核大小（kernel_size，这里是3x3的卷积核）\n",
    "        # 填充（padding，这里设置为1，即对输入的图像进行边缘填充，确保输出的宽高与输入相同）\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1) # 输入3，输入32\n",
    "        self.bn1 = nn.BatchNorm2d(32)  # 批量归一化\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) # 输入32，输出64\n",
    "        self.bn2 = nn.BatchNorm2d(64)  # 批量归一化\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1) # 输入64，输出128\n",
    "        self.bn3 = nn.BatchNorm2d(128)  # 批量归一化\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten() # 全链接层输入\n",
    "        \n",
    "        self.fc = nn.Linear(128 * 4 * 4, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 卷积、激活、池化\n",
    "        x = self.pool(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu3(self.bn3(self.conv3(x))))\n",
    "\n",
    "        # 展开为全链接层的输入\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def get_pruned_config(self):\n",
    "        \"\"\"\n",
    "        返回一个CNN剪枝厚的结构配置\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'conv1': self.conv1.out_channels,\n",
    "            'conv2': self.conv2.out_channels,\n",
    "            'conv3': self.conv3.out_channels,\n",
    "            # ...其他层...\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94d0ae-3796-4b08-b0e4-3ea832cf9614",
   "metadata": {},
   "source": [
    "## 1-2 训练CNN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c2d73-febb-45d2-a387-feefb74f9bde",
   "metadata": {},
   "source": [
    "这部分是模型训练函数，步骤如下：\n",
    "1. 数据加载\n",
    "2. 模型初始化：创建模型、损失函数和优化器\n",
    "3. 混合精度循环训练\n",
    "4. 模型保存\n",
    "\n",
    "**梯度缩放器**  \n",
    "当我们将FP32切换到FP16时，FP16可能遇到 梯度下溢（underflow）或上溢（overflow）：\n",
    "- 梯度下溢：梯度过小（特别是权重衰减时），导致更新无效。\n",
    "- 梯度上溢：梯度过大，导致 NaN 或数值不稳定。\n",
    "\n",
    "所以在scaler.scale(loss).backward()中先放大 loss（通常 × 65536），让梯度不会太小。如果发现梯度过大（上溢），就通过scaler.update()降低缩放因子，避免 NaN 发生。\n",
    "\n",
    "**训练集**  \n",
    "在训练过程中使用验证集进行验证，可以：\n",
    "- 防止过拟合（测试集精度波动降低40%）\n",
    "- 引入早停机制，节省无效训练时间（平均减少25% epoch数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd443833-d558-4164-b4f8-9d3ba4a06db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于训练早停\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48eaa162-0d8a-4e06-9f33-44dee7f27661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载和训练函数\n",
    "def train_model(model, epoch=10, target_acc=0.80, earlystop=False):\n",
    "    \"\"\"\n",
    "    数据加载 → 模型初始化 → 混合精度训练 → 模型保存\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # 记录开始时间\n",
    "    train_losses = []  # 记录每个epoch的训练loss\n",
    "    val_losses = []    # 记录验证loss\n",
    "    val_accs = []      # 记录验证准确率\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),  # 新增\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(), # 将图像转换为 PyTorch 张量，并归一化到 [0, 1] 之间。\n",
    "        # 归一化，加速收敛：推荐参数（CIFAR-10官方统计）\n",
    "        transforms.Normalize(\n",
    "            mean=[0.4914, 0.4822, 0.4465], \n",
    "            std=[0.2023, 0.1994, 0.2010]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    \"\"\"\n",
    "    CIFAR-10 数据加载:\n",
    "    batch_size=256：每个 batch 处理 256 张图像。\n",
    "    shuffle=True：打乱数据，提高训练的随机性。\n",
    "    num_workers=4：使用 4 个 CPU 线程加速数据加载（根据硬件情况调整）。\n",
    "    pin_memory=True：提升 GPU 数据传输效率（如果使用 GPU）。\n",
    "    prefetch_factor=2：预取 2 个 batch，减少 I/O 阻塞，提高训练速度。\n",
    "    \"\"\"\n",
    "    # 训练集加载\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=2)\n",
    "    # 验证集加载\n",
    "    valset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "    valloader = torch.utils.data.DataLoader(valset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    # 定义损失函数：nn.CrossEntropyLoss() 适用于分类任务，它会计算 Softmax + 交叉熵损失。\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    \"\"\"\n",
    "    优化器选择SGD：\n",
    "    lr=0.01：学习率。\n",
    "    momentum=0.9：添加动量项，减少震荡，提高收敛速度。\n",
    "    weight_decay=5e-4：L2 正则化（防止过拟合）。\n",
    "    nesterov=True：使用 Nesterov 动量，比普通 SGD 更稳定。\n",
    "    \"\"\"\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4, nesterov=True)  # 采用 SGD + Nesterov\n",
    "\n",
    "    # 余弦退火调度器\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        T_max=200,    # 半周期长度\n",
    "        eta_min=1e-4  # 最小学习率\n",
    "    )\n",
    "    \n",
    "    scaler = GradScaler() # 启用混合精度训练\n",
    "    early_stopper = EarlyStopping(patience=3) # 早停机制\n",
    "    \n",
    "    for epoch in range(epoch):\n",
    "        model.train() # 训练模式，自动启用 dropout和BatchNorm\n",
    "        epoch_train_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in trainloader:\n",
    "            # inputs和labels是 CPU 张量，需要 .to(device) 传输到GPU\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # PyTorch 默认梯度是累积的，因此每次训练前必须清零。\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # autocast() 使计算采用 FP16 进行前向传播，减少显存占用，加速训练。\n",
    "            with autocast():  \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                epoch_train_loss += loss.item() * inputs.size(0)  # 新增\n",
    "\n",
    "            # 使用梯度缩放进行反向传播\n",
    "            scaler.scale(loss).backward() # 缩放 loss，使 FP16 计算更稳定。\n",
    "            scaler.step(optimizer) # 更新模型参数。\n",
    "            scaler.update() # 动态调整 scaler，确保数值稳定性。\n",
    "\n",
    "        # 计算并记录训练loss   \n",
    "        epoch_train_loss /= len(trainset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "    \n",
    "        if earlystop:\n",
    "            model.eval() # 验证模式\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in valloader:\n",
    "                    # 计算loss\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    val_loss += criterion(outputs, labels).item()\n",
    "                    # 计算acc\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            val_acc = 100 * correct / total\n",
    "            val_loss /= len(valloader)\n",
    "\n",
    "            # 新增记录\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(val_acc)\n",
    "            print(f\"Epoch {epoch}: Train Loss={epoch_train_loss:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.2f}%\")\n",
    "                \n",
    "            # 触发早停\n",
    "            if early_stopper(val_loss):\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break \n",
    "\n",
    "        scheduler.step()  # 更新学习率\n",
    "        \n",
    "    # 计算总训练时长\n",
    "    end_time = time.time()  # 记录结束时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"训练完成！总耗时：{elapsed_time:.2f} 秒\")  # 显示训练时间\n",
    "\n",
    "    return {\n",
    "    'train_loss': train_losses,\n",
    "    'val_loss': val_losses,\n",
    "    'val_acc': val_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6aa25f6-12d2-4093-958a-4319af9131bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss=1.4991, Val Loss=1.3506, Val Acc=54.10%\n",
      "Epoch 1: Train Loss=1.0991, Val Loss=1.1281, Val Acc=60.90%\n",
      "Epoch 2: Train Loss=0.9653, Val Loss=1.1150, Val Acc=60.97%\n",
      "Epoch 3: Train Loss=0.8843, Val Loss=1.0601, Val Acc=63.66%\n",
      "Epoch 4: Train Loss=0.8238, Val Loss=0.9526, Val Acc=66.91%\n",
      "Epoch 5: Train Loss=0.7870, Val Loss=0.8734, Val Acc=68.74%\n",
      "Epoch 6: Train Loss=0.7538, Val Loss=0.8619, Val Acc=70.25%\n",
      "Epoch 7: Train Loss=0.7213, Val Loss=0.8509, Val Acc=70.38%\n",
      "Epoch 8: Train Loss=0.7043, Val Loss=0.8534, Val Acc=70.63%\n",
      "Epoch 9: Train Loss=0.6811, Val Loss=0.8017, Val Acc=72.25%\n",
      "训练完成！总耗时：114.72 秒\n"
     ]
    }
   ],
   "source": [
    "# 创建模型：使用全局device，模型直接创建在GPU上\n",
    "model = SimpleCNN().to(device)\n",
    "metrics = train_model(model, epoch=10, earlystop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c995f7be-bde9-4a73-940a-e8e9fcbadbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制训练曲线\n",
    "plt.plot(metrics['train_loss'], label='Train Loss')\n",
    "plt.plot(metrics['val_loss'], label='Val Loss')\n",
    "plt.plot(metrics['val_acc'], label='Val Acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05149ac6-63c3-4f56-92d9-bfcc2c6add1c",
   "metadata": {},
   "source": [
    "## 1-3 模型保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216acfbf-80d9-4d8f-92a4-7c902e9628d6",
   "metadata": {},
   "source": [
    "为了方便后面剪枝的进行，需要自定义模型保存方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d778ac5-9702-4898-97a7-1dc593cc18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prune_mask(model):\n",
    "    \"\"\"生成各层的剪枝掩码（示例：随机剪枝50%）\"\"\"\n",
    "    masks = {}\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            out_channels = layer.out_channels\n",
    "            # 生成随机掩码（实际应替换为GA的剪枝决策）\n",
    "            masks[name] = torch.rand(out_channels) > 0.5  \n",
    "    return masks\n",
    "\n",
    "# 自定义结构保存格式\n",
    "def save_pruned_model(model, mask_dict, name='pruned_model.pth'):\n",
    "    \"\"\" mask_dict: 记录各层保留通道的布尔掩码 \"\"\"\n",
    "    torch.save({\n",
    "        'state_dict': model.state_dict(),\n",
    "        'model_arch': model.get_pruned_config(),  # 需自定义方法\n",
    "        'mask': mask_dict\n",
    "    }, 'pruned_model.pth')\n",
    "\n",
    "def load_pruned_model(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model = SimpleCNN()  # 原始结构\n",
    "    \n",
    "    # 应用剪枝\n",
    "    pruned_model = prune_model(\n",
    "        model, \n",
    "        masks=checkpoint['mask'],\n",
    "        config=checkpoint['model_arch']\n",
    "    )\n",
    "    pruned_model.load_state_dict(checkpoint['state_dict'])\n",
    "    return pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d695420-3b99-4b6d-a842-b6027505a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = generate_prune_mask(model)  # 实际应由遗传算法生成\n",
    "save_pruned_model(model, mask, 'ga_pruned_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0615125d-9690-4dee-ad1e-63a44a153431",
   "metadata": {},
   "source": [
    "# 2 基于DEAP配置遗传算法\n",
    "## 2-1 配置个体和种群"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ccb8de-6e1d-4f66-9ea4-a80bf7b60780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_ga_toolbox(model, seed=42):\n",
    "    \"\"\"\n",
    "    配置遗传算法工具箱\n",
    "    :param model: 目标CNN模型实例（需继承nn.Module）\n",
    "    :param seed: 随机种子（默认42）\n",
    "    :return: 配置完成的DEAP toolbox对象\n",
    "    \"\"\"\n",
    "    # ===== 动态计算染色体长度 =====\n",
    "    def get_chromosome_length():\n",
    "        return sum(layer.out_channels for layer in model.modules() \n",
    "                 if isinstance(layer, torch.nn.Conv2d))\n",
    "    # ===== 基因有效性校验 =====\n",
    "    def validate_gene(indiv):\n",
    "        ptr = 0\n",
    "        for layer in model.modules():\n",
    "            if isinstance(layer, torch.nn.Conv2d):\n",
    "                genes = indiv[ptr : ptr+layer.out_channels]\n",
    "                if sum(genes) == 0:  # 通道全0保护\n",
    "                    indiv[ptr + random.randint(0, layer.out_channels-1)] = 1\n",
    "                ptr += layer.out_channels\n",
    "        return indiv\n",
    "      \n",
    "    # 设置随机种子\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # 计算gene长度\n",
    "    n = get_chromosome_length()\n",
    "    \n",
    "    # ===== 创建遗传算法组件 =====\n",
    "    # 防止重复创建报错\n",
    "    if \"FitnessMax\" in creator.__dict__:\n",
    "        del creator.FitnessMax\n",
    "    if \"Individual\" in creator.__dict__:\n",
    "        del creator.Individual\n",
    "\n",
    "    # 定义适应度类型: FitnessMax表示最大化单目标\n",
    "    # weights指定优化方向：正值表示最大化，负值最小化。weights=(1.0,)表示单目标优化的权重。如果是weights=(1.0, -1.0)，那就是双目标优化\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    # 定义个体类型：列表存储基因序列 + 附加适应度属性\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    \"\"\"\n",
    "    注册个体生成方法\n",
    "    个体类型：creator.Individual\n",
    "    生成器：tools.initIterate | 通过迭代器构造对象 | 适用于需要复杂初始化逻辑的场景\n",
    "    生成器：tools.initRepeat | 重复调用构造函数生成集合 | 适用于批量生成相同结构的对象\n",
    "    lambda函数：生成经过验证的基因序列，再包装成creator.Individual的实例\n",
    "    \"\"\"\n",
    "    toolbox.register(\"individual\", tools.initIterate, creator.Individual,\n",
    "                   lambda: validate_gene(\n",
    "                       [torch.randint(0,2,(1,)).item() for _ in range(n)]\n",
    "                   )) # 使用PyTorch的randint替代Python原生随机\n",
    "    # 注册种群生成方法\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    return toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cd82248-79dd-4f67-ac42-d4eeea6776ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "种群大小: 50, 染色体长度: 224\n"
     ]
    }
   ],
   "source": [
    "toolbox = configure_ga_toolbox(model, seed=42)\n",
    "\n",
    "# 生成测试种群\n",
    "population = toolbox.population(n=50)  # 生成50个个体的种群\n",
    "print(f\"种群大小: {len(population)}, 染色体长度: {len(population[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231345c4-57c8-4f03-83d1-886bbc1abd3b",
   "metadata": {},
   "source": [
    "## 2-2 配置选择-交叉-变异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2c513-08b2-4cc8-b231-d0e130bb5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 evaluate()适应度函数注册到 toolbox，这样 Deap 在进化时会自动调用 evaluate() 评估个体适应度。\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "# 添加CUDA并行评估\n",
    "import torch.multiprocessing as mp  # 使用 PyTorch 兼容的多进程库\n",
    "pool = mp.Pool(processes=min(torch.cuda.device_count(), 4))  # 限制最大并行进程数\n",
    "toolbox.register(\"map\", pool.map)\n",
    "\n",
    "# 交叉-变异-选择\n",
    "toolbox.register(\"mate\", tools.cxUniform, indpb=0.5)  # 均匀交叉\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)  # 0.1的变异概率\n",
    "toolbox.register(\"select\", tools.selBest, k=5)  # 只保留最优个体，加快收敛速度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6318ebb-adaf-44c8-a4be-462dcd035ac9",
   "metadata": {},
   "source": [
    "## 3：定义剪枝和评估函数\n",
    "这一部分的任务是加载预训练模型并定义剪枝逻辑及适应度评估。  \n",
    "修改了以下几个地方：\n",
    "1. clone()之前先.to(device)，可以减少不必要的 GPU 计算图拷贝\n",
    "2. 自动适配 device，确保 original_model 和 pruned_model 在同一设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2df177fe-8ac5-4eb3-8e31-724c690fddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(original_model, conv1_indices, conv2_indices):\n",
    "    \"\"\"基于剪枝索引创建新的CNN模型，并高效转移权重\"\"\"\n",
    "    \n",
    "    # 自动获取原始模型所在设备\n",
    "    device = original_model.conv1.weight.device  \n",
    "\n",
    "    # 如果 conv1_indices 为空，则返回 None 并释放显存\n",
    "    if not conv1_indices or len(conv1_indices) == 0:\n",
    "        torch.cuda.empty_cache()  # 释放显存\n",
    "        return None\n",
    "    \n",
    "    # 创建剪枝后的模型，放在相同的设备上\n",
    "    pruned_model = SimpleCNN().to(device)\n",
    "    \n",
    "    # 剪枝 Conv1（确保索引合法）\n",
    "    pruned_model.conv1.weight.data = original_model.conv1.weight.data[conv1_indices].to(device).clone()\n",
    "    pruned_model.conv1.bias.data = original_model.conv1.bias.data[conv1_indices].to(device).clone()\n",
    "\n",
    "    # 如果 conv2_indices 为空，则返回 None 并释放显存\n",
    "    if not conv2_indices or len(conv2_indices) == 0:\n",
    "        del pruned_model\n",
    "        torch.cuda.empty_cache()\n",
    "        return None\n",
    "\n",
    "    # 剪枝 Conv2，确保权重索引正确（同时剪枝输入通道和输出通道）\n",
    "    pruned_model.conv2.weight.data = (\n",
    "        original_model.conv2.weight.data[conv2_indices][:, conv1_indices, :, :].to(device).clone()\n",
    "    )\n",
    "    pruned_model.conv2.bias.data = original_model.conv2.bias.data[conv2_indices].to(device).clone()\n",
    "\n",
    "    # 剪枝 Conv3（仅修改输入通道，不剪枝输出通道）\n",
    "    pruned_model.conv3.weight.data = original_model.conv3.weight.data[:, :len(conv2_indices), :, :].to(device).clone()\n",
    "    pruned_model.conv3.bias.data = original_model.conv3.bias.data.to(device).clone()\n",
    "\n",
    "    # 复制全连接层权重（FC 层通常不剪枝）\n",
    "    pruned_model.fc.weight.data = original_model.fc.weight.data.to(device).clone()\n",
    "    pruned_model.fc.bias.data = original_model.fc.bias.data.to(device).clone()\n",
    "\n",
    "    return pruned_model  # 返回剪枝后的新模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce97189-1f89-4ae4-a036-0a72e1681e2f",
   "metadata": {},
   "source": [
    "优化：\n",
    "1. 显式调用 gc.collect() 清理 Python 对象引用\n",
    "2. 使用 with torch.no_grad() 加速推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4b638f6-2c49-41fb-9d6a-d3e22d771241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 是否启用 debug 输出\n",
    "DEBUG = False  \n",
    "\n",
    "def evaluate(individual):\n",
    "    \"\"\"评估剪枝后模型的适应度（基于准确率）\"\"\"\n",
    "    \n",
    "    if DEBUG:\n",
    "        print(\"Evaluating individual:\", individual)\n",
    "\n",
    "    # 解码染色体（获得要保留的卷积核索引）\n",
    "    conv1_indices = [i for i, bit in enumerate(individual[:64]) if bit == 1]\n",
    "    conv2_indices = [i for i, bit in enumerate(individual[64:192]) if bit == 1]\n",
    "    \n",
    "    # 约束：如果某层没有保留任何卷积核，则适应度设为 0\n",
    "    if not conv1_indices or not conv2_indices:\n",
    "        torch.cuda.empty_cache()  # 仅在需要时释放显存\n",
    "        return (0,)\n",
    "\n",
    "    # 加载预训练模型到 GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    original_model = SimpleCNN().to(device)\n",
    "    original_model.load_state_dict(torch.load('pretrained_model.pth', map_location=device))\n",
    "\n",
    "    try:\n",
    "        # 剪枝模型\n",
    "        pruned_model = prune_model(original_model, conv1_indices, conv2_indices)\n",
    "        if pruned_model is None:\n",
    "            torch.cuda.empty_cache()\n",
    "            return (0,)\n",
    "\n",
    "        # 评估剪枝后模型的准确率（加速推理）\n",
    "        with torch.no_grad():\n",
    "            accuracy = test_accuracy(pruned_model)\n",
    "\n",
    "        # 显存清理（确保显式释放）\n",
    "        del original_model, pruned_model\n",
    "        gc.collect()  # 释放 Python 对象\n",
    "        torch.cuda.empty_cache()  # 释放 GPU 缓存\n",
    "\n",
    "        return (accuracy,)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        if \"CUDA out of memory\" in str(e):\n",
    "            print(f\"显存溢出: {str(e)}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            return (0,)\n",
    "        else:\n",
    "            raise e  # 抛出其他异常，避免静默失败"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde616ba-9fe3-4457-b7bf-0f3a2ba8e7f5",
   "metadata": {},
   "source": [
    "优化：\n",
    "1. 使用CPU的4核来优化数据加载\n",
    "2. 增加AMP自动混合精度：用torch.autocast()启用FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8b0650a-df65-45f1-81c2-72e80ba8e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model):\n",
    "    \"\"\"评估模型在测试集上的准确率\"\"\"\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # 只在数据未下载时下载，避免重复检查\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "\n",
    "    # 优化数据加载：使用并行加载和固定内存\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=256, shuffle=False, num_workers=4, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 确保 `model` 和 `inputs` 在相同设备上\n",
    "    device = next(model.parameters()).device\n",
    "    if next(model.parameters()).device != device:\n",
    "        model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 启用 AMP 进行 FP16 推理，提高计算速度\n",
    "    with torch.no_grad(), torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "        for inputs, labels in testloader:\n",
    "            # 异步传输数据到 GPU\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total  # 返回准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a1de56-72f3-493d-84f9-a40af95f65c9",
   "metadata": {},
   "source": [
    "优化：\n",
    "1. 这里我限制了最大进程数为4，避免开太多进程导致 CUDA 争用（除非你有 4 块 GPU）。通常 4 个并行进程足够充分调用1 张 GPU。\n",
    "2. 在选择策略中只保留最有个体，尽可能加快收敛速度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9775ca-8f90-48c0-ae7c-41e481c21b93",
   "metadata": {},
   "source": [
    "## 4：运行遗传算法剪枝\n",
    "优化：\n",
    "1. 使用 starmap 并行计算（避免 map 在某些平台上性能下降）。或使用 `executor.map()`并行计算适应度（轻量级线程池）\n",
    "2. 使用 torch.jit.script 编译 evaluate()，加速适应度计算\n",
    "3. 减少 NGEN（遗传代数）但增加 population（种群规模），让GPU更忙。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4762c93-7096-429c-b7d1-88a347f70913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_genetic_algorithm(population_size=100, ngen=10, cxpb=0.7, mutpb=0.1):\n",
    "    \"\"\"\n",
    "    执行遗传算法优化 CNN 剪枝\n",
    "    :param population_size: 种群大小\n",
    "    :param ngen: 遗传代数\n",
    "    :param cxpb: 交叉概率\n",
    "    :param mutpb: 变异概率\n",
    "    :return: 最佳个体\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"运行遗传算法: 交叉率 {cxpb}, 变异率 {mutpb}, 代数 {ngen}, 种群规模 {population_size}\")\n",
    "    \n",
    "    # **初始化种群**\n",
    "    population = toolbox.population(n=population_size)\n",
    "\n",
    "    try:\n",
    "        with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            for gen in range(ngen):\n",
    "                print(f\"Generation {gen+1}/{ngen} 开始\")\n",
    "\n",
    "                # **交叉 & 变异**\n",
    "                offspring = algorithms.varAnd(population, toolbox, cxpb, mutpb)\n",
    "\n",
    "                # **并行计算适应度**\n",
    "                fits = list(executor.map(toolbox.evaluate, offspring))\n",
    "                for fit, ind in zip(fits, offspring):\n",
    "                    ind.fitness.values = fit\n",
    "\n",
    "                # **精英保留策略**\n",
    "                elite = tools.selBest(population, k=2)\n",
    "                offspring = toolbox.select(offspring, k=len(population) - len(elite))\n",
    "                population = elite + offspring\n",
    "\n",
    "                print(f\"Generation {gen+1}/{ngen} 结束\\n\")\n",
    "\n",
    "        # **返回最佳个体**\n",
    "        best_ind = tools.selBest(population, k=1)[0]\n",
    "        return best_ind\n",
    "\n",
    "    finally:\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        print(\"遗传算法完成，释放资源\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb3cf44-5cf9-4550-a23b-b715bedf42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"主函数，调用遗传算法，并保存最佳剪枝方案和模型\"\"\"\n",
    "    start_time = time.time()  # 记录开始时间\n",
    "    \n",
    "    # 运行遗传算法\n",
    "    best_ind = run_genetic_algorithm(population_size=20, ngen=1, cxpb=0.5, mutpb=0.05)\n",
    "\n",
    "    # 保存最佳个体\n",
    "    with open(\"best_individual.pkl\", \"wb\") as f:\n",
    "        pickle.dump(best_ind, f)\n",
    "    print(f\"已保存最佳剪枝方案: best_individual.pkl\")\n",
    "\n",
    "    # 剪枝 CNN 并保存模型\n",
    "    original_model = SimpleCNN().to(device)\n",
    "    original_model.load_state_dict(torch.load('pretrained_model.pth', map_location=device))\n",
    "\n",
    "    # 解码 `best_ind` 并应用剪枝\n",
    "    conv1_indices = [i for i, bit in enumerate(best_ind[:64]) if bit == 1]\n",
    "    conv2_indices = [i for i, bit in enumerate(best_ind[64:192]) if bit == 1]\n",
    "    pruned_model = prune_model(original_model, conv1_indices, conv2_indices)\n",
    "\n",
    "    # 保存剪枝后的模型\n",
    "    if pruned_model:\n",
    "        torch.save(pruned_model.state_dict(), \"pruned_model.pth\")\n",
    "        print(f\"剪枝后模型已保存: pruned_model.pth\")\n",
    "    else:\n",
    "        print(\"剪枝后模型无效（可能所有通道都被剪枝），未保存！\")\n",
    "\n",
    "    end_time = time.time()  # 记录结束时间\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"训练完成！总耗时：{elapsed_time:.2f} 秒\")  # 显示训练时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d14c39a-3a74-45f9-bcc2-91d1c8ba625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行遗传算法: 交叉率 0.7, 变异率 0.1, 代数 1, 种群规模 20\n",
      "Generation 1/1 开始\n",
      "遗传算法完成，释放资源\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 25\u001b[0m, in \u001b[0;36mrun_genetic_algorithm\u001b[0;34m(population_size, ngen, cxpb, mutpb)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# **并行计算适应度**\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m fits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoolbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffspring\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fit, ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(fits, offspring):\n",
      "File \u001b[0;32m~/eais-miniconda/lib/python3.8/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/eais-miniconda/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/eais-miniconda/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39mbenchmark \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# 启用 cuDNN 自动优化\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"主函数，调用遗传算法，并保存最佳剪枝方案和模型\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 运行遗传算法\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m best_ind \u001b[38;5;241m=\u001b[39m \u001b[43mrun_genetic_algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mngen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcxpb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutpb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 保存最佳个体\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_individual.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "Cell \u001b[0;32mIn[32], line 34\u001b[0m, in \u001b[0;36mrun_genetic_algorithm\u001b[0;34m(population_size, ngen, cxpb, mutpb)\u001b[0m\n\u001b[1;32m     31\u001b[0m         offspring \u001b[38;5;241m=\u001b[39m toolbox\u001b[38;5;241m.\u001b[39mselect(offspring, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(population) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(elite))\n\u001b[1;32m     32\u001b[0m         population \u001b[38;5;241m=\u001b[39m elite \u001b[38;5;241m+\u001b[39m offspring\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mngen\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 结束\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# **返回最佳个体**\u001b[39;00m\n\u001b[1;32m     37\u001b[0m best_ind \u001b[38;5;241m=\u001b[39m tools\u001b[38;5;241m.\u001b[39mselBest(population, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/eais-miniconda/lib/python3.8/concurrent/futures/_base.py:644\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/eais-miniconda/lib/python3.8/concurrent/futures/thread.py:236\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 236\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eais-miniconda/lib/python3.8/threading.py:1011\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/eais-miniconda/lib/python3.8/threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# already determined that the C code is done\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[0;32m-> 1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1028\u001b[0m     lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    torch.backends.cudnn.benchmark = True  # 启用 cuDNN 自动优化\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03dd7148-f9a4-41df-828e-89ff016f0749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功关闭 multiprocessing 进程池\n",
      "CUDA 显存缓存已清理\n"
     ]
    }
   ],
   "source": [
    "# 终止进程池（如果还在运行）\n",
    "try:\n",
    "    pool.terminate()\n",
    "    pool.join()\n",
    "    print(\"已成功关闭 multiprocessing 进程池\")\n",
    "except:\n",
    "    print(\"未找到正在运行的 multiprocessing 进程\")\n",
    "\n",
    "# 清理 CUDA 缓存\n",
    "torch.cuda.empty_cache()\n",
    "print(\"CUDA 显存缓存已清理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598c8d6-4aad-4004-939c-bcb29c5929df",
   "metadata": {},
   "source": [
    "## 5：微调剪枝后的模型\n",
    "\n",
    "剪枝后的模型要使用微调，而不是重新训练。如果重新训练的话，那剪枝不就没有意义了吗？\n",
    "对找到的最佳剪枝模型进行微调以恢复性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7a097b4-672a-4c3d-a2a2-da6d833be3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune(pruned_model):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    pruned_model.to(device)  # 确保模型在GPU\n",
    "    optimizer = optim.SGD(pruned_model.parameters(), lr=0.0001)\n",
    "    \n",
    "    # 使用混合精度训练\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        pruned_model.train()\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():  # 自动混合精度\n",
    "                outputs = pruned_model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "    \n",
    "    return pruned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf6765b-5918-4b58-bf3f-4b70788dc63d",
   "metadata": {},
   "source": [
    "# 6：测试性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8873c12b-38be-4656-9458-e5506426a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    评估 CNN 模型（剪枝前/剪枝后）：\n",
    "    1. 计算在 CIFAR-10 测试集上的准确率\n",
    "    2. 统计 FLOPs（计算量）和参数量\n",
    "    \"\"\"\n",
    "    # **确保模型在 GPU 上**\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # **测试集预处理**\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # **加载 CIFAR-10 测试集**\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    # **推理加速**\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()  # 计时\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            # **启用 FP16 计算加速**\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # **计算准确率**\n",
    "    accuracy = 100 * correct / total\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"\\n{model_name} 评估结果:\")\n",
    "    print(f\"{model_name} 准确率: {accuracy:.2f}%\")\n",
    "    print(f\"推理时间: {end_time - start_time:.4f} 秒\")\n",
    "\n",
    "    # **统计模型的 FLOPs & 参数量**\n",
    "    print(\"\\n模型统计信息:\")\n",
    "    summary(model, input_size=(1, 3, 32, 32), device=device)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75289882-f1c9-4743-92ed-671cb35a0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models():\n",
    "    \"\"\"对比未剪枝模型和剪枝模型的性能\"\"\"\n",
    "\n",
    "    # **加载未剪枝模型**\n",
    "    original_model = SimpleCNN().to(device)\n",
    "    original_model.load_state_dict(torch.load(\"pretrained_model.pth\", map_location=device))\n",
    "    \n",
    "    # **加载剪枝后的模型**\n",
    "    pruned_model = SimpleCNN().to(device)\n",
    "    pruned_model.load_state_dict(torch.load(\"pruned_model.pth\", map_location=device))\n",
    "\n",
    "    # **评估二者性能**\n",
    "    acc_original = evaluate_model(original_model, \"未剪枝模型\")\n",
    "    acc_pruned = evaluate_model(pruned_model, \"剪枝后模型\")\n",
    "\n",
    "    # **性能对比**\n",
    "    print(\"\\n**剪枝前后模型性能对比**\")\n",
    "    print(f\"未剪枝模型准确率: {acc_original:.2f}%\")\n",
    "    print(f\"剪枝后模型准确率: {acc_pruned:.2f}%\")\n",
    "    print(f\"剪枝后模型的准确率下降: {acc_original - acc_pruned:.2f}%**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f5c37-a884-4ba5-9b63-885d8c62130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True  # 启用 cuDNN 自动优化\n",
    "compare_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
